{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed/miniconda3/envs/dolly/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from instruct_pipeline import InstructionTextGenerationPipeline\n",
    "os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model output is:  Nuclear fission and fusion are different types of nuclear fission. Nuclear fission occurs when atomic nuclei split into pieces and nuclear fission is what happens when nuclei split into nuclear fragments. Nuclear fusion occurs when atomic nuclei merge into pieces. Nuclear fusion happens when atomic nuclei unite into fragments. Nuclear fission is also referred to as explosion or explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as fission. Nuclear fusion is also known as fusion. Nuclear fission is also known as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also known as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as fusion. Nuclear fission is also referred to as explosion. Nuclear fusion is also known as\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "pretrained_dir = 'checkpoints/sparse_dolly_12/' # 1:2 sparsity\n",
    "model_name = 'databricks/dolly-v2-12b'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_dir, torch_dtype=torch.half).to(device)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "generate_text = InstructionTextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"Explain to me the difference between nuclear fission and fusion.\"\n",
    "with torch.no_grad():\n",
    "    res = generate_text(text)\n",
    "print('The model output is: ', res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of zero parameters in dense layers of model: 49.993\n"
     ]
    }
   ],
   "source": [
    "def count_ratio_zero_param(cur_model):\n",
    "    torch.cuda.empty_cache()  # Clear any unused memory to get accurate results\n",
    "    torch.cuda.reset_peak_memory_stats(device)  # Reset peak memory stats\n",
    "    torch.cuda.synchronize(device)  # Wait for all operations to finish\n",
    "    gc.collect()\n",
    "    param, zero_param = 0, 0\n",
    "    for name, p in cur_model.named_parameters():\n",
    "        if 'dense' in name or 'query_key_value' in name:\n",
    "            param += p.numel()\n",
    "            zero_param += torch.sum(p==0).item()\n",
    "    return (zero_param/param)*100.0\n",
    "print('Ratio of zero parameters in dense layers of model: {:.3f}'.format(count_ratio_zero_param(model.cpu())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5663969280 11326279680\n",
      "Ratio of New model to old model: 50.007\n"
     ]
    }
   ],
   "source": [
    "def compress_weights(W):\n",
    "    W = W.detach().numpy()\n",
    "    rows, cols = W.shape\n",
    "    sparsity_mask = (W != 0)\n",
    "\n",
    "    x = np.random.randn(cols, 1)\n",
    "    a = W @ x\n",
    "\n",
    "    V = W[sparsity_mask.astype(bool)].reshape(rows, cols // 2)\n",
    "    P = V[np.newaxis, ...]*x.reshape(cols// 2, 2).T[:, np.newaxis, :]\n",
    "    Q = P * sparsity_mask.reshape(-1, 2).T.reshape(2, rows, cols // 2)\n",
    "    b = np.sum(Q, axis=(0, 2))\n",
    "    assert np.allclose(a.flatten(), b) == True\n",
    "    assert cols//2==V.shape[1]\n",
    "    return V\n",
    "\n",
    "\n",
    "def verify_dolly_sparsity(cur_model):\n",
    "    torch.cuda.empty_cache()  # Clear any unused memory to get accurate results\n",
    "    torch.cuda.reset_peak_memory_stats(device)  # Reset peak memory stats\n",
    "    torch.cuda.synchronize(device)  # Wait for all operations to finish\n",
    "    gc.collect()\n",
    "    param, new_param = 0, 0\n",
    "    for name, p in cur_model.named_parameters():\n",
    "        if 'dense' in name or 'query_key_value' in name:\n",
    "            if len(p.shape)>1:\n",
    "                V = compress_weights(p)\n",
    "                new_param += V.size\n",
    "            else:\n",
    "                new_param+=p.numel()\n",
    "            param += p.numel()\n",
    "    return new_param, param\n",
    "new_param, param = verify_dolly_sparsity(model.cpu())\n",
    "print(new_param, param)\n",
    "print('Ratio of New model to old model: {:.3f}'.format((new_param/param)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_attn = model.gpt_neox.layers[2].attention.query_key_value.weight.data\n",
    "# sparsity_mask = (cur_attn != 0).cpu().numpy()\n",
    "# rows, cols = cur_attn.shape\n",
    "# W = cur_attn.cpu().numpy()\n",
    "# x = np.random.randn(cols, 1)\n",
    "# a = W @ x\n",
    "\n",
    "# V = W[sparsity_mask.astype(bool)].reshape(rows, cols // 2)\n",
    "# P = V[np.newaxis, ...]*x.reshape(cols// 2, 2).T[:, np.newaxis, :]\n",
    "# Q = P * sparsity_mask.reshape(-1, 2).T.reshape(2, rows, cols // 2)\n",
    "# b = np.sum(Q, axis=(0, 2))\n",
    "# print(np.allclose(a.flatten(), b))\n",
    "# print(cur_attn.shape, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the ratio of zeros in cur_attn\n",
    "# cur_attn = model.gpt_neox.layers[2].attention.query_key_value.weight.data\n",
    "# ratio_zeros = (torch.sum(cur_attn == 0).item() / cur_attn.numel()) * 100.0\n",
    "# print('Ratio of zero parameters in current attention layer: {:.3f}%'.format(ratio_zeros))\n",
    "# print(cur_attn.shape)\n",
    "# print(cur_attn[:10, :5])\n",
    "# # Plot the values of the attention matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(cur_attn[:10, :10].cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
